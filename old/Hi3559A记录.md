# Hi3559

## 交叉编译器

官方提供的aarch64-himix100-linux.tgz，解压后有个xxx.install，修改其中第一行即可修改其安装目录，sudo运行后即安装完成。

运行时发现无论怎么弄都是No such file or directory，后来明白（https://blog.csdn.net/tudou2013goodluck/article/details/83270805）是由于提供的交叉编译器需要32位的库，于是需要安装lib32z1-dev，离线安装实在太慢了费了点力气

ftp，由于Hi3559A的文件系统不支持ssh和ftp，所以需要用telnet和ftp，对于ftp，可以使用命令

```bash
ftp 192.165.53.198
```

也可以

```bash
ftp
ftp> open 192.165.53.198
```

传输文件

```bash
ftp> put xxx.xxx
```

## 初跑demo

跑了一个示例sample_ive_main，一堆参数不知道都是什么功能，简单看看文档分析一下：

0)BgModel. Background Model，背景建模

1)Gmm. Guassian Mixture Model，亦称Mixture of Guassian，MOG，高斯混合模型，应用最多的背景建模算法

2)Occlusion detected. 遮挡检测

3)Motion detected.  运动检测

4)Canny. 边缘检测canny算法

5)Gmm2. 看着像是另一个高斯混合模型，即MOG2

6)MemoryTest. 

7)Sobel. 图像处理的sobel算子

8)Ann. Artificial Neural Network，人工神经网络

9)St Lk. st不知道，LK可能是流光算子

a)Svm. Support Vector Machine，支持向量机

b)Cnn. Convolutional Neural Network，卷积神经网络

链接：

https://blog.csdn.net/App_12062011/article/details/51843036

由于文件系统太小，所以挂载一个nfs这样空间大一些

```bash
ifconfig eth0 192.165.53.198;route add default gw 192.165.53.1;mount -t nfs  -o nolock 192.165.53.15:/opt/DVRRDK_04.00.00.03/target/rfs/opt/jiangdongchao /opt/autorun
```

有一些ko需要加载，这些需要

```bash
mount -t nfs -o nolock 192.165.53.15:/opt/DVRRDK_04.00.00.03/target/rfs/opt/lixin_40173/HI3559A/20190918/ko /ko
cd /ko;cp /opt/autorun/load3559av100_multicore_1536M ./load3559av100_multicore;./load3559av100_multicore -i -sensor0 imx477 -sensor1 imx477
```

这些准备好之后就可以尝试一些命令了：

```bash
./sample_ive_main 0 0 1  # BgModel 似乎是实时的，报错[SAMPLE_IVE_ViToVo]-343: Error(0xa007800e),HI_MPI_VPSS_GetChnFrame failed, VPSS_GRP(0), VPSS_CHN(1)!
./sample_ive_main 1 0 1  # gmm 同上
./sample_ive_main 2  # Occlusion detected 同上
./sample_ive_main 3  # Motion detected 同上
./sample_ive_main 4 0  # canny 360*576 422
./sample_ive_main 5  # gmm2 176*288 422
./sample_ive_main 6  # MemoryTest
./sample_ive_main 7  # Sobel 360*576 422 - 360*1152
./sample_ive_main 8  # ann 16*32 400
./sample_ive_main 9  # st lk 720*576 420 没有输出
./sample_ive_main a  # svm 16*32 400
./sample_ive_main b  # cnn 20*40 400
```

 后来尝试了sample_vio，发现还是有问题，调整了vo的配置，sample_comm_vo.c的978行

```c
pstVoConfig->enIntfSync        = VO_OUTPUT_1080P60;
```

输出可以识别了，同时可以根据设置的背景颜色在显示器上进行输出，但是依旧没有采集。

尝试了sample_venc，依旧，并且确认没有采集到数据，怀疑摄像头有问题，于是不再进行处理，切换到HL3000的板子上继续进行。

操作步骤，启动，串口修改ip，然后执行/opt/autorun/autorun.sh_debug，会配置一些东西以及加载驱动等，然后就可以跑了

需要修改一些输入输出的参数，源是8120出来的，最高只能设置到720P，显示器不支持1080P30，需要修改

ive这块的程序在输入输出上是统一的，可以统一配置输入和输出，另外由于当前用的是HL3000，所以注意要用的宏是什么

接下来运行就正常了，可以正常输出经过检测的视频，motion检测的效果比较显著，接下来可以看看代码

会记录一些概念

VB是video buffer

注意sample2 中的venc的getsensorxxx的里面sensor0的参数被写死了，如果需要的话后面要改改

一般它都是一个vi接一个vpss，然后后续处理时会在两个vpss通道分别取视频帧， 其中一帧是vi同大小的，用于最终的输出（可能会在其上进行一定的修改），另一个是经过vpss缩放的，过大影响处理效率，缩小了进行处理，处理后的数据有可能再应用到先前的视频帧上。

## 尝试分析各个功能的具体效果

Canny，即坎尼边缘检测器，最后输出的是IVE_IMAGE_S的二值图像，写到文件后可以以Y400进行查看，两条API，需要依次调用

Motion Detect，即运动检测，只有明显运动的才会触发

Sobel，创建 5x5 模板 Sobel-like 梯度计算任务 ，Canny里面也用到了梯度计算，不知道与这个有没有关系

Gmm和Gmm2都是可以将前景图像指针与背景图像指针分离开，对于Gmm，描述为【创建 GMM 背景建模任务，支持灰度图、 RGB_PACKAGE 图像的 GMM 背景建模， 高
斯模型个数为 3 或者 5。 】，对于Gmm2，描述为【创建 GMM 背景建模任务，支持 1-5 个高斯模型，支持灰度图和 RGB_PACKAGE 图输
入， 支持全局及像素级别的灵敏度系数以及前景模型时长更新系数。 】

BgModel，描述为【基于 Codebook 演进的背景模型匹配。 】，我的理解上与Gmm和Gmm2是一个概念，CodeBook的基本思路是得到每个像素的时间序列模型。这种模型能很好地处理时间起伏，缺点是需要消耗大量的内存，给每个像素建立时间起伏模型，算法没细看

Occlusion detect，遮盖检测，似乎没有专用的API，是通过一系列计算来判断的

ST LK，LK为Lucas-Kanade 光流，画面移动中像素的位移量，两个假设，1运动物体的灰度在很短的时间内保持不变，2给定邻域内的速度向量场变化是缓慢的。应该是亮度的运动跟踪相关的，具体算法没详细看；ST应该是角点检测的Shi-Tomasi角点检测，给的demo中，只是简单调用了一下，具体用途不是很清晰。

ANN，看接口是ann mlp，即神经网络多层感知器，demo是读入yuv将其分类，模型的训练怕是得自己另外训练，比如windows opencv训练得到xml，然后通过海思提供的工具ive_tool_xml2bin.exe 转换为bin

## 再深入些了解算法

### Codebook背景建模

算法描述用于彩色图，但小幅修改后也适用于灰度图，$\mathcal X$为包含了$N$个RGB向量的单个像素的训练序列$\mathcal X=\{\bold{x}_1,\bold{x}_2,...,\bold{x}_N\}$，$\mathcal C$表示由$L$个CW组成的CB，$\mathcal{C}=\{\bold{c}_1,\bold{c}_2,...,\bold{c}_L\}$，每个像素的CB大小不一定一样，每个CW由一个RGB向量$\bold{v}_i=(\bar{R_i},\bar{G_i},\bar{B_i})$和一个6元组$\bold{aux}_i=\lang\check{I}_i,\hat{I}_i,f_i,\lambda_i,p_i,q_i\rang$

- $\check{I_i},\hat{I_i}$，该CW对应的像素的亮度最大值和最小值
- $f$，该CW出现频率
- $\lambda$，最大负游程（MNRL），定义为训练周期内CW未重复出现的最长间隔
- $p,q$，该CW首次和末次出现的时间

训练周期内，将每个时刻的像素与CB进行比较，找到匹配的那个，具体算法如下

1. $L\leftarrow0,\mathcal C\leftarrow\varnothing$

2. $\bold{for}\ i=1\ to\ N\ \bold{do}$

   1. $\bold{x}_t=(R,G,B),I=\sqrt{R^2+G^2+B^2}$
   2. 在$\mathcal{C}=\{\bold{c}_i|1\leq i\leq L\}$中找到使 $ \bold{x}_t$满足以下两个条件的CB $\bold{c}_m$
      1. $colorlist(\bold{x}_t,\bold{v}_m)\leq\varepsilon_1$
      2. $brightness(I,\lang\check{I}_m,\hat{I}_m\rang)=\bold{true}$
   3. 如果$\mathcal{C}=\varnothing$或者找不到满足条件的CB，令$L\leftarrow L+1$，创建新的CB $\bold{c}_L$，并令
      1. $\bold{v}_L\leftarrow(R,G,B)$
      2. $\bold{aux}_L\leftarrow\lang I,I,1,t-1,t,t\rang$
   4. 否则，更新满足条件的CB $\bold{c}_m$由$\bold{v}_m=(\bar{R_i},\bar{G_i},\bar{B_i})$和$\bold{aux}_m=\lang\check{I}_m,\hat{I}_m,f_m,\lambda_m,p_m,q_m\rang$组成
      1. $\bold{v}_m\leftarrow(\frac{f_m\bar{R_m}+R}{f_m+1},\frac{f_m\bar{G_m}+G}{f_m+1},\frac{f_m\bar{B_m}+B}{f_m+1})$
      2. $\bold{aux}_m\leftarrow\lang\min\{I,\check{I}_m\},\max\{I,\hat{I}_m\},f_m+1,\max\{\lambda_m,t-q_m\},p_m,t\rang$

   $\bold{end\ for}$

3. 对于每个$\bold{c}_i,i=1,...,L$，设$\lambda_i\leftarrow\max\{\lambda_i,(N-q_i+p_i-1)\}$来wrap around $ \lambda_i$

这个太多了，下班再搞，先看吧

### GMM2

考虑到性能，目前基本上选定GMM2了，接下来就是针对GMM2进行一些优化，使之尽量能与OpenCV的MOG2的效果接近，分析一下执行流程